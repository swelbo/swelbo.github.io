{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Shotgun metagenomic analysis for salient.bio technical challenge. For files and full documentation please visit github.com/swelbo . Prerequisites snakemake - Pipeline management tool. fastqc - Check read quality scores. multiqc - Snazzy report of read qualities. cutadapt - Remove pesky remaining illumina adapters. bbmap split - Clean reads of Illumina Phix control (and host check with cpu). bbmap merge - Merge paired end reads whilist retaining reads that could not be paird. metaphlan3 - Taxonomic profiling of samples. humann - Functional characterisation of the metagenome. Package installation conda create -n sbint python=3.7 # Create conda environment conda install metaphlan humann cutadapt multiqc fastqc # Install prequisite packages Step QC: Check the quality of the FASTQ files using FASTQC in BASH mkdir fastqc fastqc reads/* -o fastqc/ # run fastqc over all read samples multiqc fastqc/ -o multiqc # generate snazzy report cp multiqc/multiqc_report.html Snakemake pipeline Workflow Step 1: Addition of the samples list and target file. SAMPLES = [\"Sample_A\", \"Sample_B\", \"Sample_C\", \"Sample_D\", \"Sample_E\", \"Sample_F\", \"Sample_G\", \"Sample_H\", \"Sample_I\", \"Sample_J\", \"Sample_K\", \"Sample_L\"] # Target file rule all: input: \"/Users/tsewell/sb_int/metaphlan/merged/merged_abundance_table.txt\" Step 2: Cutadapt to remove last remaining adapters (consider using BBduk here) rule trim: input: r1 = \"/Users/tsewell/sb_int/reads/{sample}_L001_R1_001_subsample.fastq.gz\", r2 = \"/Users/tsewell/sb_int/reads/{sample}_L001_R2_001_subsample.fastq.gz\" output: trim1 = \"/Users/tsewell/sb_int/trimmed/{sample}.trimmed.R1.fastq\", trim2 = \"/Users/tsewell/sb_int/trimmed/{sample}.trimmed.R2.fastq\" shell: \"(cutadapt -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA -A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT -o {output.trim1} -p {output.trim2} {input.r1} {input.r2})\" Step 3: Filter PhiX control from data rule hostfilter: input: fq1 = \"/Users/tsewell/sb_int/trimmed/{sample}.trimmed.R1.fastq\", fq2 = \"/Users/tsewell/sb_int/trimmed/{sample}.trimmed.R2.fastq\", contam = \"/Users/tsewell/sb_int/reference/GCF_000819615.1_ViralProj14015_genomic.fna.gz\" output: clean1 = \"/Users/tsewell/sb_int/cleaned/{sample}.clean_1.fq\", clean2 = \"/Users/tsewell/sb_int/cleaned/{sample}.clean_2.fq\" shell: \"/Users/tsewell/bbmap/bbsplit.sh -Xmx16g in1={input.fq1} in2={input.fq2} ref={input.contam} outu1={output.clean1} outu2={output.clean2} int=t\" Step 4: Merge paired reads rule merge: input: cleanfq1 = \"/Users/tsewell/sb_int/cleaned/{sample}.clean_1.fq\", cleanfq2 = \"/Users/tsewell/sb_int/cleaned/{sample}.clean_2.fq\" output: merged = \"/Users/tsewell/sb_int/merged/{sample}.merged.fq\", hist = \"/Users/tsewell/sb_int/merged/{sample}.ihist.txt\", unmerged = \"/Users/tsewell/sb_int/merged/{sample}.unmerged.fq\" shell: \"/Users/tsewell/bbmap/bbmerge-auto.sh in1={input.cleanfq1} in2={input.cleanfq2} out={output.merged} outu={output.unmerged} ihist={output.hist} ecct extend2=20 iterations=5 mix=f\" Step 5: Map reads to the metaphlan database for taxonomic analysis - use two cores rule metaphlan: input: fasta = \"/Users/tsewell/sb_int/merged/{sample}.merged.fq\" output: meta = \"/Users/tsewell/sb_int/metaphlan/{sample}.metagenome.txt\", bow = \"/Users/tsewell/sb_int/merged/{sample}.merged.fq.bowtie2out.txt\" shell: \"metaphlan {input.fasta} --input_type fastq --nproc 2 > {output.meta} --unknown_estimation --bowtie2db /Users/tsewell/metaphlan_db/\" Step 6: Merge abundances into a single tab seperated txt file rule merge_metaphlan: input: expand(\"/Users/tsewell/sb_int/metaphlan/{sample}.metagenome.txt\", sample=SAMPLES) output: \"/Users/tsewell/sb_int/metaphlan/merged/merged_abundance_table.txt\" shell: \"merge_metaphlan_tables.py {input} > {output}\" Full snakemake pipline # config file SAMPLES = [\"Sample_A\", \"Sample_B\", \"Sample_C\", \"Sample_D\", \"Sample_E\", \"Sample_F\", \"Sample_G\", \"Sample_H\", \"Sample_I\", \"Sample_J\", \"Sample_K\", \"Sample_L\"] # Target file - RULE ALL HERE rule all: input: \"/Users/tsewell/sb_int/metaphlan/merged/merged_abundance_table.txt\" # Step 1 Cutadapt rule trim: input: r1 = \"/Users/tsewell/sb_int/reads/{sample}_L001_R1_001_subsample.fastq.gz\", r2 = \"/Users/tsewell/sb_int/reads/{sample}_L001_R2_001_subsample.fastq.gz\" output: trim1 = \"/Users/tsewell/sb_int/trimmed/{sample}.trimmed.R1.fastq\", trim2 = \"/Users/tsewell/sb_int/trimmed/{sample}.trimmed.R2.fastq\" shell: \"(cutadapt -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA -A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT -o {output.trim1} -p {output.trim2} {input.r1} {input.r2})\" #MAYBE BBDUK HERE # Step 2 Filter host/PhiX rule hostfilter: input: fq1 = \"/Users/tsewell/sb_int/trimmed/{sample}.trimmed.R1.fastq\", fq2 = \"/Users/tsewell/sb_int/trimmed/{sample}.trimmed.R2.fastq\", contam = \"/Users/tsewell/sb_int/reference/GCF_000819615.1_ViralProj14015_genomic.fna.gz\" output: clean1 = \"/Users/tsewell/sb_int/cleaned/{sample}.clean_1.fq\", clean2 = \"/Users/tsewell/sb_int/cleaned/{sample}.clean_2.fq\" shell: \"/Users/tsewell/bbmap/bbsplit.sh -Xmx16g in1={input.fq1} in2={input.fq2} ref={input.contam} outu1={output.clean1} outu2={output.clean2} int=t\" # Step 3 Merge paired reads rule merge: input: cleanfq1 = \"/Users/tsewell/sb_int/cleaned/{sample}.clean_1.fq\", cleanfq2 = \"/Users/tsewell/sb_int/cleaned/{sample}.clean_2.fq\" output: merged = \"/Users/tsewell/sb_int/merged/{sample}.merged.fq\", hist = \"/Users/tsewell/sb_int/merged/{sample}.ihist.txt\", unmerged = \"/Users/tsewell/sb_int/merged/{sample}.unmerged.fq\" shell: \"/Users/tsewell/bbmap/bbmerge-auto.sh in1={input.cleanfq1} in2={input.cleanfq2} out={output.merged} outu={output.unmerged} ihist={output.hist} ecct extend2=20 iterations=5 mix=f\" # Step 4 map reads to the metaphlan databaase for taxonomic analysis - use two cores rule metaphlan: input: fasta = \"/Users/tsewell/sb_int/merged/{sample}.merged.fq\" output: meta = \"/Users/tsewell/sb_int/metaphlan/{sample}.metagenome.txt\", bow = \"/Users/tsewell/sb_int/merged/{sample}.merged.fq.bowtie2out.txt\" shell: \"metaphlan {input.fasta} --input_type fastq --nproc 2 > {output.meta} --unknown_estimation --bowtie2db /Users/tsewell/metaphlan_db/\" # Step 5 - Merge abundances into a single tab seperated txt file rule merge_metaphlan: input: expand(\"/Users/tsewell/sb_int/metaphlan/{sample}.metagenome.txt\", sample=SAMPLES) output: \"/Users/tsewell/sb_int/metaphlan/merged/merged_abundance_table.txt\" shell: \"merge_metaphlan_tables.py {input} > {output}\" Step 7 Extract species level abundances from merged txt file grep -E \"s__|clade\" merged_abundance_table.txt | sed 's/^.*s__//g'\\ | cut -f1,3-14 | sed -e 's/clade_name/body_site/g' > merged_abundance_table_species.txt Extract species level abundances including UNKNOWN portion grep -E \"UNKNOWN|s__|clade\" merged_abundance_table.txt | sed 's/^.*s__//g'\\ | cut -f1,3-14 | sed -e 's/clade_name/body_site/g' > merged_abundance_table_species_unknown.txt Extract genus level abundances including UNKNOWN portion grep -E \"UNKNOWN|g__|clade\" merged_abundance_table.txt | sed 's/^.*g__//g;/s__/d' | cut -f1,3-14 | sed -e 's/clade_name/body_site/g' > merged_abundance_table_genus_unknown.txt Step 8 Functional analysis Build this into the snakemake pipeline for i in User/tsewell/sb_int/merged/Sample_*.merged.fq; do humann --input $i --output ${i%.merged.fq} --threads 4 --metaphlan-options \"--unknown_estimation --bowtie2db /Users/tsewell/metaphlan_db/; done Normalise RPK values by copies per million (CPM) for i in Sample_*.merged_genefamilies.tsv; do humann_renorm_table --input $i --output ${i%.tsv}-cpm.tsv --units cpm --update-snames; done Regroup UNIREF calls into RNX values (MetaCyc) for i in Sample_*.merged_genefamilies-cpm.tsv; do humann_regroup_table --input $i --output ${i%.tsv}.rxn-cpm.tsv --groups uniref90_rxn; done Name the RXN features so they arae human readable for i in Sample_*.merged_genefamilies-cpm.rxn-cpm.tsv; do humann_rename_table --input $i --output ${i%.tsv}-named.tsv --names metacyc-rxn; done","title":"Analysis"},{"location":"#shotgun-metagenomic-analysis-for-salientbio-technical-challenge","text":"For files and full documentation please visit github.com/swelbo .","title":"Shotgun metagenomic analysis for salient.bio technical challenge."},{"location":"#prerequisites","text":"snakemake - Pipeline management tool. fastqc - Check read quality scores. multiqc - Snazzy report of read qualities. cutadapt - Remove pesky remaining illumina adapters. bbmap split - Clean reads of Illumina Phix control (and host check with cpu). bbmap merge - Merge paired end reads whilist retaining reads that could not be paird. metaphlan3 - Taxonomic profiling of samples. humann - Functional characterisation of the metagenome.","title":"Prerequisites"},{"location":"#package-installation","text":"conda create -n sbint python=3.7 # Create conda environment conda install metaphlan humann cutadapt multiqc fastqc # Install prequisite packages","title":"Package installation"},{"location":"#step-qc","text":"","title":"Step QC:"},{"location":"#check-the-quality-of-the-fastq-files-using-fastqc-in-bash","text":"mkdir fastqc fastqc reads/* -o fastqc/ # run fastqc over all read samples multiqc fastqc/ -o multiqc # generate snazzy report cp multiqc/multiqc_report.html","title":"Check the quality of the FASTQ files using FASTQC in BASH"},{"location":"#snakemake-pipeline","text":"","title":"Snakemake pipeline"},{"location":"#workflow","text":"","title":"Workflow"},{"location":"#step-1","text":"","title":"Step 1:"},{"location":"#addition-of-the-samples-list-and-target-file","text":"SAMPLES = [\"Sample_A\", \"Sample_B\", \"Sample_C\", \"Sample_D\", \"Sample_E\", \"Sample_F\", \"Sample_G\", \"Sample_H\", \"Sample_I\", \"Sample_J\", \"Sample_K\", \"Sample_L\"] # Target file rule all: input: \"/Users/tsewell/sb_int/metaphlan/merged/merged_abundance_table.txt\"","title":"Addition of the samples list and target file."},{"location":"#step-2","text":"","title":"Step 2:"},{"location":"#cutadapt-to-remove-last-remaining-adapters-consider-using-bbduk-here","text":"rule trim: input: r1 = \"/Users/tsewell/sb_int/reads/{sample}_L001_R1_001_subsample.fastq.gz\", r2 = \"/Users/tsewell/sb_int/reads/{sample}_L001_R2_001_subsample.fastq.gz\" output: trim1 = \"/Users/tsewell/sb_int/trimmed/{sample}.trimmed.R1.fastq\", trim2 = \"/Users/tsewell/sb_int/trimmed/{sample}.trimmed.R2.fastq\" shell: \"(cutadapt -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA -A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT -o {output.trim1} -p {output.trim2} {input.r1} {input.r2})\"","title":"Cutadapt to remove last remaining adapters (consider using BBduk here)"},{"location":"#step-3","text":"","title":"Step 3:"},{"location":"#filter-phix-control-from-data","text":"rule hostfilter: input: fq1 = \"/Users/tsewell/sb_int/trimmed/{sample}.trimmed.R1.fastq\", fq2 = \"/Users/tsewell/sb_int/trimmed/{sample}.trimmed.R2.fastq\", contam = \"/Users/tsewell/sb_int/reference/GCF_000819615.1_ViralProj14015_genomic.fna.gz\" output: clean1 = \"/Users/tsewell/sb_int/cleaned/{sample}.clean_1.fq\", clean2 = \"/Users/tsewell/sb_int/cleaned/{sample}.clean_2.fq\" shell: \"/Users/tsewell/bbmap/bbsplit.sh -Xmx16g in1={input.fq1} in2={input.fq2} ref={input.contam} outu1={output.clean1} outu2={output.clean2} int=t\"","title":"Filter PhiX control from data"},{"location":"#step-4","text":"","title":"Step 4:"},{"location":"#merge-paired-reads","text":"rule merge: input: cleanfq1 = \"/Users/tsewell/sb_int/cleaned/{sample}.clean_1.fq\", cleanfq2 = \"/Users/tsewell/sb_int/cleaned/{sample}.clean_2.fq\" output: merged = \"/Users/tsewell/sb_int/merged/{sample}.merged.fq\", hist = \"/Users/tsewell/sb_int/merged/{sample}.ihist.txt\", unmerged = \"/Users/tsewell/sb_int/merged/{sample}.unmerged.fq\" shell: \"/Users/tsewell/bbmap/bbmerge-auto.sh in1={input.cleanfq1} in2={input.cleanfq2} out={output.merged} outu={output.unmerged} ihist={output.hist} ecct extend2=20 iterations=5 mix=f\"","title":"Merge paired reads"},{"location":"#step-5","text":"","title":"Step 5:"},{"location":"#map-reads-to-the-metaphlan-database-for-taxonomic-analysis-use-two-cores","text":"rule metaphlan: input: fasta = \"/Users/tsewell/sb_int/merged/{sample}.merged.fq\" output: meta = \"/Users/tsewell/sb_int/metaphlan/{sample}.metagenome.txt\", bow = \"/Users/tsewell/sb_int/merged/{sample}.merged.fq.bowtie2out.txt\" shell: \"metaphlan {input.fasta} --input_type fastq --nproc 2 > {output.meta} --unknown_estimation --bowtie2db /Users/tsewell/metaphlan_db/\"","title":"Map reads to the metaphlan database for taxonomic analysis - use two cores"},{"location":"#step-6","text":"","title":"Step 6:"},{"location":"#merge-abundances-into-a-single-tab-seperated-txt-file","text":"rule merge_metaphlan: input: expand(\"/Users/tsewell/sb_int/metaphlan/{sample}.metagenome.txt\", sample=SAMPLES) output: \"/Users/tsewell/sb_int/metaphlan/merged/merged_abundance_table.txt\" shell: \"merge_metaphlan_tables.py {input} > {output}\"","title":"Merge abundances into a single tab seperated txt file"},{"location":"#full-snakemake-pipline","text":"# config file SAMPLES = [\"Sample_A\", \"Sample_B\", \"Sample_C\", \"Sample_D\", \"Sample_E\", \"Sample_F\", \"Sample_G\", \"Sample_H\", \"Sample_I\", \"Sample_J\", \"Sample_K\", \"Sample_L\"] # Target file - RULE ALL HERE rule all: input: \"/Users/tsewell/sb_int/metaphlan/merged/merged_abundance_table.txt\" # Step 1 Cutadapt rule trim: input: r1 = \"/Users/tsewell/sb_int/reads/{sample}_L001_R1_001_subsample.fastq.gz\", r2 = \"/Users/tsewell/sb_int/reads/{sample}_L001_R2_001_subsample.fastq.gz\" output: trim1 = \"/Users/tsewell/sb_int/trimmed/{sample}.trimmed.R1.fastq\", trim2 = \"/Users/tsewell/sb_int/trimmed/{sample}.trimmed.R2.fastq\" shell: \"(cutadapt -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA -A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT -o {output.trim1} -p {output.trim2} {input.r1} {input.r2})\" #MAYBE BBDUK HERE # Step 2 Filter host/PhiX rule hostfilter: input: fq1 = \"/Users/tsewell/sb_int/trimmed/{sample}.trimmed.R1.fastq\", fq2 = \"/Users/tsewell/sb_int/trimmed/{sample}.trimmed.R2.fastq\", contam = \"/Users/tsewell/sb_int/reference/GCF_000819615.1_ViralProj14015_genomic.fna.gz\" output: clean1 = \"/Users/tsewell/sb_int/cleaned/{sample}.clean_1.fq\", clean2 = \"/Users/tsewell/sb_int/cleaned/{sample}.clean_2.fq\" shell: \"/Users/tsewell/bbmap/bbsplit.sh -Xmx16g in1={input.fq1} in2={input.fq2} ref={input.contam} outu1={output.clean1} outu2={output.clean2} int=t\" # Step 3 Merge paired reads rule merge: input: cleanfq1 = \"/Users/tsewell/sb_int/cleaned/{sample}.clean_1.fq\", cleanfq2 = \"/Users/tsewell/sb_int/cleaned/{sample}.clean_2.fq\" output: merged = \"/Users/tsewell/sb_int/merged/{sample}.merged.fq\", hist = \"/Users/tsewell/sb_int/merged/{sample}.ihist.txt\", unmerged = \"/Users/tsewell/sb_int/merged/{sample}.unmerged.fq\" shell: \"/Users/tsewell/bbmap/bbmerge-auto.sh in1={input.cleanfq1} in2={input.cleanfq2} out={output.merged} outu={output.unmerged} ihist={output.hist} ecct extend2=20 iterations=5 mix=f\" # Step 4 map reads to the metaphlan databaase for taxonomic analysis - use two cores rule metaphlan: input: fasta = \"/Users/tsewell/sb_int/merged/{sample}.merged.fq\" output: meta = \"/Users/tsewell/sb_int/metaphlan/{sample}.metagenome.txt\", bow = \"/Users/tsewell/sb_int/merged/{sample}.merged.fq.bowtie2out.txt\" shell: \"metaphlan {input.fasta} --input_type fastq --nproc 2 > {output.meta} --unknown_estimation --bowtie2db /Users/tsewell/metaphlan_db/\" # Step 5 - Merge abundances into a single tab seperated txt file rule merge_metaphlan: input: expand(\"/Users/tsewell/sb_int/metaphlan/{sample}.metagenome.txt\", sample=SAMPLES) output: \"/Users/tsewell/sb_int/metaphlan/merged/merged_abundance_table.txt\" shell: \"merge_metaphlan_tables.py {input} > {output}\"","title":"Full snakemake pipline"},{"location":"#step-7","text":"","title":"Step 7"},{"location":"#extract-species-level-abundances-from-merged-txt-file","text":"grep -E \"s__|clade\" merged_abundance_table.txt | sed 's/^.*s__//g'\\ | cut -f1,3-14 | sed -e 's/clade_name/body_site/g' > merged_abundance_table_species.txt","title":"Extract species level abundances from merged txt file"},{"location":"#extract-species-level-abundances-including-unknown-portion","text":"grep -E \"UNKNOWN|s__|clade\" merged_abundance_table.txt | sed 's/^.*s__//g'\\ | cut -f1,3-14 | sed -e 's/clade_name/body_site/g' > merged_abundance_table_species_unknown.txt","title":"Extract species level abundances including UNKNOWN portion"},{"location":"#extract-genus-level-abundances-including-unknown-portion","text":"grep -E \"UNKNOWN|g__|clade\" merged_abundance_table.txt | sed 's/^.*g__//g;/s__/d' | cut -f1,3-14 | sed -e 's/clade_name/body_site/g' > merged_abundance_table_genus_unknown.txt","title":"Extract genus level abundances including UNKNOWN portion"},{"location":"#step-8","text":"","title":"Step 8"},{"location":"#functional-analysis","text":"","title":"Functional analysis"},{"location":"#build-this-into-the-snakemake-pipeline","text":"for i in User/tsewell/sb_int/merged/Sample_*.merged.fq; do humann --input $i --output ${i%.merged.fq} --threads 4 --metaphlan-options \"--unknown_estimation --bowtie2db /Users/tsewell/metaphlan_db/; done","title":"Build this into the snakemake pipeline"},{"location":"#normalise-rpk-values-by-copies-per-million-cpm","text":"for i in Sample_*.merged_genefamilies.tsv; do humann_renorm_table --input $i --output ${i%.tsv}-cpm.tsv --units cpm --update-snames; done","title":"Normalise RPK values by copies per million (CPM)"},{"location":"#regroup-uniref-calls-into-rnx-values-metacyc","text":"for i in Sample_*.merged_genefamilies-cpm.tsv; do humann_regroup_table --input $i --output ${i%.tsv}.rxn-cpm.tsv --groups uniref90_rxn; done","title":"Regroup UNIREF calls into RNX values (MetaCyc)"},{"location":"#name-the-rxn-features-so-they-arae-human-readable","text":"for i in Sample_*.merged_genefamilies-cpm.rxn-cpm.tsv; do humann_rename_table --input $i --output ${i%.tsv}-named.tsv --names metacyc-rxn; done","title":"Name the RXN features so they arae human readable"},{"location":"Analysis/","text":"Results Table of taxonomic abundances Figure 1 Stacked bar plot representing percentage abundance at the species level R Code please click here for code # Load packages library(ggplot2) library(dplyr) # input merged abundance data sb_df <- read.csv(file = \"~/sb_int/metaphlan/merged/merged_abundance_table_species_long.txt\") # gross conversion to percentage (fix this with loop) sL <- as.data.frame((sb_df$value[1:32]/sum(sb_df$value[1:32]))*100) colnames(sL) <- c(\"Percentage\") sK <- as.data.frame((sb_df$value[33:64]/sum(sb_df$value[33:64]))*100) colnames(sK) <- c(\"Percentage\") sJ <- as.data.frame((sb_df$value[65:96]/sum(sb_df$value[65:96]))*100) colnames(sJ) <- c(\"Percentage\") sI <- as.data.frame((sb_df$value[97:128]/sum(sb_df$value[97:128]))*100) colnames(sI) <- c(\"Percentage\") sH <- as.data.frame((sb_df$value[129:160]/sum(sb_df$value[129:160]))*100) colnames(sH) <- c(\"Percentage\") sG <- as.data.frame((sb_df$value[161:192]/sum(sb_df$value[161:192]))*100) colnames(sG) <- c(\"Percentage\") sF <- as.data.frame((sb_df$value[193:224]/sum(sb_df$value[193:224]))*100) colnames(sF) <- c(\"Percentage\") sE <- as.data.frame((sb_df$value[225:256]/sum(sb_df$value[225:256]))*100) colnames(sE) <- c(\"Percentage\") sD <- as.data.frame((sb_df$value[257:288]/sum(sb_df$value[257:288]))*100) colnames(sD) <- c(\"Percentage\") sC <- as.data.frame((sb_df$value[289:320]/sum(sb_df$value[289:320]))*100) colnames(sC) <- c(\"Percentage\") sB <- as.data.frame((sb_df$value[321:352]/sum(sb_df$value[321:352]))*100) colnames(sB) <- c(\"Percentage\") sA <- as.data.frame((sb_df$value[353:384]/sum(sb_df$value[353:384]))*100) colnames(sA) <- c(\"Percentage\") # concat dataframes new <- rbind(sL, sK, sJ, sI, sH, sG, sF, sE, sD, sC, sB, sA) # add to main dataframe sb_df_percentage <- cbind(sb_df, new) # edit column names colnames(sb_df_percentage) <- c(\"No\", \"Bacterial_species\", \"Sample\", \"Abundance\", \"Percentage\") sb_df_percentage # Stacked hori <- ggplot(sb_df_percentage, aes(fill = Bacterial_species, y = Sample, x = Percentage)) + geom_bar(position = \"stack\", stat = \"identity\") hori # colours eeep! c33 <- c( \"dodgerblue2\", \"#E31A1C\", # red \"green4\", \"#6A3D9A\", # purple \"#FF7F00\", # orange \"black\", \"gold1\", \"skyblue2\", \"#FB9A99\", # lt pink \"palegreen2\", \"#CAB2D6\", # lt purple \"#FDBF6F\", # lt orange \"gray70\", \"khaki2\", \"maroon\", \"orchid1\", \"deeppink1\", \"blue1\", \"steelblue4\", \"darkturquoise\", \"green1\", \"yellow4\", \"yellow3\", \"darkorange4\", \"brown\", \"dodgerblue2\", \"tomato3\", \"green4\", \"mediumorchid3\", \"lightsalmon\", # orange \"grey50\",\"lightskyblue4\") # new colours + classic theme hori.final <- hori + scale_fill_manual(values=c33) + theme_classic() hori.final # plot final PCA plot and save to file png(\"sb_int/mkdoc_sbint/docs/figs/species_stacked.png\", width = 1100, height = 400) hori.final dev.off() Figure 2 Stacked bar plot representing percentage abundance at the genus level, including unknown portion R code please click here for code ##### Genus stacked bar plot (with unknown portion) ##### # input merged species level abundance data genus_df <- read.csv(file = \"~/sb_int/metaphlan/merged/merged_abundance_table_genus_unknown_long.csv\") # edit column names colnames(genus_df) <- c(\"No\", \"Genus\", \"Sample\", \"Percentage abundance\") genus_df # remove .metagenome from sample name genus_df <- genus_df %>% mutate(Sample = str_remove(Sample, \".metagenome\")) # initial ggplot hori <- ggplot(genus_df, aes(fill = Genus, y = Sample, x = `Percentage abundance`)) + geom_bar(position = \"stack\", stat = \"identity\") hori # colours eeep! c21 <- c(\"#FF7F00\", # orange \"black\", \"gold1\", \"skyblue2\", \"#FB9A99\", # lt pink \"palegreen2\", \"#CAB2D6\", # lt purple \"#FDBF6F\", # lt orange \"gray70\", \"khaki2\", \"maroon\", \"orchid1\", \"deeppink1\", \"blue1\", \"steelblue4\", \"darkturquoise\", \"green1\", \"yellow4\", \"yellow3\",\"#ebd8bd\", \"darkorange4\") # new colours + classic theme hori.genus.final <- hori + scale_fill_manual(values=c21) + theme_classic() + theme(axis.text=element_text(size=12), axis.title=element_text(size=14,face=\"bold\"), legend.text=element_text(size=16)) hori.genus.final # plot final PCA plot and save to file png(\"sb_int/mkdoc_sbint/docs/figs/genus_stacked.png\", width = 1100, height = 600) hori.genus.final dev.off() Figure 3 PCA visulised using first two principal components. Kmeans clustering used to predict community structure. Perhaps the samples are 4 replicates of three gut microbiome samples? R code please click here for code ## load libraries library(tidyverse) library(vegan) # input merged abundance data sb_df <- read.csv(file = \"~/sb_int/metaphlan/merged/merged_abundance_table_species.txt\", sep = \"\\t\") sb_df # convert to a matrix sb_mat = sb_df %>% column_to_rownames(\"body_site\") %>% as.matrix() %>% t() ## PCA Plot # Generate a distance matrix based on abundance dist_mat = vegdist(sb_mat, method = \"manhattan\") # Multidimensional scaling of the matrix (PCA) cmd_res = cmdscale(dist_mat, k = (nrow(sb_mat) - 1), eig = TRUE) # check data structure str(cmd_res) # Select first two principal coordinates pca_df = tibble(PC1 = cmd_res$points[,1], PC2 = cmd_res$points[,2]) # k means clustering to predicted community structure (cohorts from here on) set.seed(100) x <- kmeans(dist_mat, centers = 3) kmeans <- as.data.frame(x$cluster) kmeans$`x$cluster`[kmeans$`x$cluster` == \"1\"] <- \"A\" kmeans$`x$cluster`[kmeans$`x$cluster` == \"2\"] <- \"B\" kmeans$`x$cluster`[kmeans$`x$cluster` == \"3\"] <- \"C\" colnames(kmeans) <- \"Patient (predicition)\" kmeans # Add the predicted cohort as meta data to PCOA dataframe pca_meta <- bind_cols(pca_df, kmeans) pca_meta # ggplot coloured by cohort clustering pca_plot <- ggplot(pca_meta, aes(x = PC1, y = PC2, colour = `Patient (predicition)`)) + geom_point(alpha = 0.75, size = 5) + scale_size(guide = \"none\") + scale_alpha(guide = \"none\") # plot final PCA plot and save to file png(\"sb_int/mkdoc_sbint/docs/figs/PCA_abundance_kmeans.png\", width = 450, height = 300) pca_plot dev.off() Figure 4 Cladogram of merged microbiomes with circle size representing abundance Bash commands please click here for code # Create a seperate conda package due to python2.7 dependencies conda create -n graphlan python=2.7 conda activate graphlan conda install -c biobakery graphlan conda install export2graphlan biopython # reformat abundance table tail -n +2 merged_abundance_table.txt | cut -f1,3- > merged_abundance_table_reformatted.txt # script that generates the two input files for GraPhlAn (the tree and annotation files) # export2graphlan.py -h for flag definitions export2graphlan.py --skip_rows 1 -i merged_abundance_table_reformatted.txt --tree merged_abundance.tree.txt --annotation merged_abundance.annot.txt --most_abundant 100 --abundance_threshold 1 --least_biomarkers 10 --annotations 5,6 --external_annotations 7 --min_clade_size 1 # generate .xml file graphlan_annotate.py --annot merged_abundance.annot.txt merged_abundance.tree.txt merged_abundance.xml # run phylo graphlan.py --dpi 300 merged_abundance.xml merged_abundance.png --external_legends # copy to mkdocs figs folder cp merged_abundance.png ~/sb_int/mkdoc_sbint/docs/figs/ Table 2 Normalised gene family abundance for predicted patient one (Sample A, B, G, H) Table 3 Normalised gene family abundance for predicted patient one (Sample C, D, I, J) Table 4 Normalised gene family abundance for predicted patient one (Sample E, F, K, L)","title":"Results"},{"location":"Analysis/#results","text":"","title":"Results"},{"location":"Analysis/#table-of-taxonomic-abundances","text":"","title":"Table of taxonomic abundances"},{"location":"Analysis/#figure-1","text":"","title":"Figure 1"},{"location":"Analysis/#stacked-bar-plot-representing-percentage-abundance-at-the-species-level","text":"","title":"Stacked bar plot representing percentage abundance at the species level"},{"location":"Analysis/#r-code","text":"please click here for code # Load packages library(ggplot2) library(dplyr) # input merged abundance data sb_df <- read.csv(file = \"~/sb_int/metaphlan/merged/merged_abundance_table_species_long.txt\") # gross conversion to percentage (fix this with loop) sL <- as.data.frame((sb_df$value[1:32]/sum(sb_df$value[1:32]))*100) colnames(sL) <- c(\"Percentage\") sK <- as.data.frame((sb_df$value[33:64]/sum(sb_df$value[33:64]))*100) colnames(sK) <- c(\"Percentage\") sJ <- as.data.frame((sb_df$value[65:96]/sum(sb_df$value[65:96]))*100) colnames(sJ) <- c(\"Percentage\") sI <- as.data.frame((sb_df$value[97:128]/sum(sb_df$value[97:128]))*100) colnames(sI) <- c(\"Percentage\") sH <- as.data.frame((sb_df$value[129:160]/sum(sb_df$value[129:160]))*100) colnames(sH) <- c(\"Percentage\") sG <- as.data.frame((sb_df$value[161:192]/sum(sb_df$value[161:192]))*100) colnames(sG) <- c(\"Percentage\") sF <- as.data.frame((sb_df$value[193:224]/sum(sb_df$value[193:224]))*100) colnames(sF) <- c(\"Percentage\") sE <- as.data.frame((sb_df$value[225:256]/sum(sb_df$value[225:256]))*100) colnames(sE) <- c(\"Percentage\") sD <- as.data.frame((sb_df$value[257:288]/sum(sb_df$value[257:288]))*100) colnames(sD) <- c(\"Percentage\") sC <- as.data.frame((sb_df$value[289:320]/sum(sb_df$value[289:320]))*100) colnames(sC) <- c(\"Percentage\") sB <- as.data.frame((sb_df$value[321:352]/sum(sb_df$value[321:352]))*100) colnames(sB) <- c(\"Percentage\") sA <- as.data.frame((sb_df$value[353:384]/sum(sb_df$value[353:384]))*100) colnames(sA) <- c(\"Percentage\") # concat dataframes new <- rbind(sL, sK, sJ, sI, sH, sG, sF, sE, sD, sC, sB, sA) # add to main dataframe sb_df_percentage <- cbind(sb_df, new) # edit column names colnames(sb_df_percentage) <- c(\"No\", \"Bacterial_species\", \"Sample\", \"Abundance\", \"Percentage\") sb_df_percentage # Stacked hori <- ggplot(sb_df_percentage, aes(fill = Bacterial_species, y = Sample, x = Percentage)) + geom_bar(position = \"stack\", stat = \"identity\") hori # colours eeep! c33 <- c( \"dodgerblue2\", \"#E31A1C\", # red \"green4\", \"#6A3D9A\", # purple \"#FF7F00\", # orange \"black\", \"gold1\", \"skyblue2\", \"#FB9A99\", # lt pink \"palegreen2\", \"#CAB2D6\", # lt purple \"#FDBF6F\", # lt orange \"gray70\", \"khaki2\", \"maroon\", \"orchid1\", \"deeppink1\", \"blue1\", \"steelblue4\", \"darkturquoise\", \"green1\", \"yellow4\", \"yellow3\", \"darkorange4\", \"brown\", \"dodgerblue2\", \"tomato3\", \"green4\", \"mediumorchid3\", \"lightsalmon\", # orange \"grey50\",\"lightskyblue4\") # new colours + classic theme hori.final <- hori + scale_fill_manual(values=c33) + theme_classic() hori.final # plot final PCA plot and save to file png(\"sb_int/mkdoc_sbint/docs/figs/species_stacked.png\", width = 1100, height = 400) hori.final dev.off()","title":"R Code"},{"location":"Analysis/#figure-2","text":"","title":"Figure 2"},{"location":"Analysis/#stacked-bar-plot-representing-percentage-abundance-at-the-genus-level-including-unknown-portion","text":"","title":"Stacked bar plot representing percentage abundance at the genus level, including unknown portion"},{"location":"Analysis/#r-code_1","text":"please click here for code ##### Genus stacked bar plot (with unknown portion) ##### # input merged species level abundance data genus_df <- read.csv(file = \"~/sb_int/metaphlan/merged/merged_abundance_table_genus_unknown_long.csv\") # edit column names colnames(genus_df) <- c(\"No\", \"Genus\", \"Sample\", \"Percentage abundance\") genus_df # remove .metagenome from sample name genus_df <- genus_df %>% mutate(Sample = str_remove(Sample, \".metagenome\")) # initial ggplot hori <- ggplot(genus_df, aes(fill = Genus, y = Sample, x = `Percentage abundance`)) + geom_bar(position = \"stack\", stat = \"identity\") hori # colours eeep! c21 <- c(\"#FF7F00\", # orange \"black\", \"gold1\", \"skyblue2\", \"#FB9A99\", # lt pink \"palegreen2\", \"#CAB2D6\", # lt purple \"#FDBF6F\", # lt orange \"gray70\", \"khaki2\", \"maroon\", \"orchid1\", \"deeppink1\", \"blue1\", \"steelblue4\", \"darkturquoise\", \"green1\", \"yellow4\", \"yellow3\",\"#ebd8bd\", \"darkorange4\") # new colours + classic theme hori.genus.final <- hori + scale_fill_manual(values=c21) + theme_classic() + theme(axis.text=element_text(size=12), axis.title=element_text(size=14,face=\"bold\"), legend.text=element_text(size=16)) hori.genus.final # plot final PCA plot and save to file png(\"sb_int/mkdoc_sbint/docs/figs/genus_stacked.png\", width = 1100, height = 600) hori.genus.final dev.off()","title":"R code"},{"location":"Analysis/#figure-3","text":"","title":"Figure 3"},{"location":"Analysis/#pca-visulised-using-first-two-principal-components-kmeans-clustering-used-to-predict-community-structure","text":"Perhaps the samples are 4 replicates of three gut microbiome samples?","title":"PCA visulised using first two principal components. Kmeans clustering used to predict community structure."},{"location":"Analysis/#r-code_2","text":"please click here for code ## load libraries library(tidyverse) library(vegan) # input merged abundance data sb_df <- read.csv(file = \"~/sb_int/metaphlan/merged/merged_abundance_table_species.txt\", sep = \"\\t\") sb_df # convert to a matrix sb_mat = sb_df %>% column_to_rownames(\"body_site\") %>% as.matrix() %>% t() ## PCA Plot # Generate a distance matrix based on abundance dist_mat = vegdist(sb_mat, method = \"manhattan\") # Multidimensional scaling of the matrix (PCA) cmd_res = cmdscale(dist_mat, k = (nrow(sb_mat) - 1), eig = TRUE) # check data structure str(cmd_res) # Select first two principal coordinates pca_df = tibble(PC1 = cmd_res$points[,1], PC2 = cmd_res$points[,2]) # k means clustering to predicted community structure (cohorts from here on) set.seed(100) x <- kmeans(dist_mat, centers = 3) kmeans <- as.data.frame(x$cluster) kmeans$`x$cluster`[kmeans$`x$cluster` == \"1\"] <- \"A\" kmeans$`x$cluster`[kmeans$`x$cluster` == \"2\"] <- \"B\" kmeans$`x$cluster`[kmeans$`x$cluster` == \"3\"] <- \"C\" colnames(kmeans) <- \"Patient (predicition)\" kmeans # Add the predicted cohort as meta data to PCOA dataframe pca_meta <- bind_cols(pca_df, kmeans) pca_meta # ggplot coloured by cohort clustering pca_plot <- ggplot(pca_meta, aes(x = PC1, y = PC2, colour = `Patient (predicition)`)) + geom_point(alpha = 0.75, size = 5) + scale_size(guide = \"none\") + scale_alpha(guide = \"none\") # plot final PCA plot and save to file png(\"sb_int/mkdoc_sbint/docs/figs/PCA_abundance_kmeans.png\", width = 450, height = 300) pca_plot dev.off()","title":"R code"},{"location":"Analysis/#figure-4","text":"","title":"Figure 4"},{"location":"Analysis/#cladogram-of-merged-microbiomes-with-circle-size-representing-abundance","text":"","title":"Cladogram of merged microbiomes with circle size representing abundance"},{"location":"Analysis/#bash-commands","text":"please click here for code # Create a seperate conda package due to python2.7 dependencies conda create -n graphlan python=2.7 conda activate graphlan conda install -c biobakery graphlan conda install export2graphlan biopython # reformat abundance table tail -n +2 merged_abundance_table.txt | cut -f1,3- > merged_abundance_table_reformatted.txt # script that generates the two input files for GraPhlAn (the tree and annotation files) # export2graphlan.py -h for flag definitions export2graphlan.py --skip_rows 1 -i merged_abundance_table_reformatted.txt --tree merged_abundance.tree.txt --annotation merged_abundance.annot.txt --most_abundant 100 --abundance_threshold 1 --least_biomarkers 10 --annotations 5,6 --external_annotations 7 --min_clade_size 1 # generate .xml file graphlan_annotate.py --annot merged_abundance.annot.txt merged_abundance.tree.txt merged_abundance.xml # run phylo graphlan.py --dpi 300 merged_abundance.xml merged_abundance.png --external_legends # copy to mkdocs figs folder cp merged_abundance.png ~/sb_int/mkdoc_sbint/docs/figs/","title":"Bash commands"},{"location":"Analysis/#table-2","text":"","title":"Table 2"},{"location":"Analysis/#normalised-gene-family-abundance-for-predicted-patient-one-sample-a-b-g-h","text":"","title":"Normalised gene family abundance for predicted patient one (Sample A, B, G, H)"},{"location":"Analysis/#table-3","text":"","title":"Table 3"},{"location":"Analysis/#normalised-gene-family-abundance-for-predicted-patient-one-sample-c-d-i-j","text":"","title":"Normalised gene family abundance for predicted patient one (Sample C, D, I, J)"},{"location":"Analysis/#table-4","text":"","title":"Table 4"},{"location":"Analysis/#normalised-gene-family-abundance-for-predicted-patient-one-sample-e-f-k-l","text":"","title":"Normalised gene family abundance for predicted patient one (Sample E, F, K, L)"}]}